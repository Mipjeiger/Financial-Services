version: "3.9"

services:
  minio:
    image: minio/minio
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    command: server /data --console-address ":9001"

  airflow:
    build: ./airflow
    ports:
      - "8080:8080"
    env_file: .env
    environment:
      AIRFLOW__CORE__EXECUTOR: ${AIRFLOW__CORE__EXECUTOR}
      AIRFLOW__CORE__LOAD_EXAMPLES: ${AIRFLOW__CORE__LOAD_EXAMPLES}
      AIRFLOW__CORE__DAGS_FOLDER: ${AIRFLOW__CORE__DAGS_FOLDER}

  spark:
    image: apache/spark:3.5.1-java17
    container_name: spark
    ports:
      - "8081:8080"  # Spark Web UI
      - "7077:7077"  # Spark Master
    environment:
      # MinIO S3 credentials
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_REGION}
      - AWS_ENDPOINT_URL=${AWS_ENDPOINT_URL}
    command: >
      bash -c "/opt/spark/sbin/start-master.sh && tail -f /opt/spark/logs/*"
    depends_on:
      - minio