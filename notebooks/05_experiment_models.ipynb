{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "405afd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b493355",
   "metadata": {},
   "source": [
    "# Load finance data from SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "9347116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = os.path.abspath(\"../.env\")\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "DB_USER = os.getenv(\"DB_USER\")\n",
    "DB_PASSWORD = os.getenv(\"DB_PASSWORD\")\n",
    "DB_HOST = os.getenv(\"DB_HOST\")\n",
    "DB_PORT = os.getenv(\"DB_PORT\")\n",
    "DB_NAME = os.getenv(\"DB_NAME\")\n",
    "\n",
    "engine = create_engine(\n",
    "    f\"postgresql+psycopg2://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}\"\n",
    ")\n",
    "\n",
    "finance = pd.read_sql(\"SELECT * FROM feature.finance\", engine)\n",
    "marketing = pd.read_sql(\"SELECT * FROM feature.marketing\", engine)\n",
    "feature_marketing = pd.read_sql(\"SELECT * FROM feature.marketing\", engine)\n",
    "feature_finance = pd.read_sql(\"SELECT * FROM feature.finance\", engine)\n",
    "marketing_score = pd.read_sql(\"SELECT * FROM marketing_scores\", engine)\n",
    "feature_finance_fraud = pd.read_sql(\"SELECT * FROM feature.finance_fraud_features\", engine)\n",
    "feature_marketing_fraud = pd.read_sql(\"SELECT * FROM feature.marketing_fraud_features\", engine)\n",
    "feature_fraud = pd.read_sql(\"SELECT * FROM feature.feature_fraud\", engine)\n",
    "label_fraud = pd.read_sql(\"SELECT * FROM label.fraud_label\", engine)\n",
    "feature_fraud_dataset = pd.read_sql(\"SELECT * FROM feature.training_fraud_dataset\", engine)\n",
    "finance_fraud_daily = pd.read_sql(\"SELECT * FROM feature.finance_fraud_daily\", engine)\n",
    "marketing_fraud_daily = pd.read_sql(\"SELECT * FROM feature.marketing_fraud_daily\", engine)\n",
    "feature_fraud_daily = pd.read_sql(\"SELECT * FROM feature.feature_fraud_daily\", engine)\n",
    "fraud_label_daily = pd.read_sql(\"SELECT * FROM label.fraud_label_daily\", engine)\n",
    "training_fraud_daily = pd.read_sql(\"SELECT * FROM feature.training_fraud_daily\", engine)\n",
    "daily_fraud_alert = pd.read_sql(\"SELECT * FROM alert.daily_fraud_alert\", engine)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "45fbb358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 41188 entries, 0 to 41187\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   user_id              41188 non-null  object \n",
      " 1   event_date           41188 non-null  object \n",
      " 2   tx_count             41188 non-null  int64  \n",
      " 3   total_tx_amount      41188 non-null  float64\n",
      " 4   avg_tx_amount        41188 non-null  float64\n",
      " 5   max_tx_amount        41188 non-null  float64\n",
      " 6   std_tx_amount        41188 non-null  float64\n",
      " 7   avg_account_balance  41188 non-null  float64\n",
      " 8   total_clicks         41188 non-null  int64  \n",
      " 9   total_impressions    41188 non-null  int64  \n",
      " 10  total_conversion     41188 non-null  int64  \n",
      " 11  ctr                  41188 non-null  float64\n",
      " 12  weekday              41188 non-null  float64\n",
      " 13  month                41188 non-null  float64\n",
      " 14  year                 41188 non-null  float64\n",
      " 15  fraud_label          41188 non-null  int64  \n",
      "dtypes: float64(9), int64(5), object(2)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# main dataset\n",
    "df = feature_fraud_dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ad70551c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>event_date</th>\n",
       "      <th>tx_count</th>\n",
       "      <th>total_tx_amount</th>\n",
       "      <th>avg_tx_amount</th>\n",
       "      <th>max_tx_amount</th>\n",
       "      <th>std_tx_amount</th>\n",
       "      <th>avg_account_balance</th>\n",
       "      <th>total_clicks</th>\n",
       "      <th>total_impressions</th>\n",
       "      <th>total_conversion</th>\n",
       "      <th>ctr</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>fraud_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA13249</td>\n",
       "      <td>2025-12-25</td>\n",
       "      <td>464</td>\n",
       "      <td>234972720.0</td>\n",
       "      <td>506406.724138</td>\n",
       "      <td>4963146.0</td>\n",
       "      <td>1.040360e+06</td>\n",
       "      <td>575492.148707</td>\n",
       "      <td>222</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>222.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AA16259</td>\n",
       "      <td>2025-12-25</td>\n",
       "      <td>464</td>\n",
       "      <td>234972720.0</td>\n",
       "      <td>506406.724138</td>\n",
       "      <td>4963146.0</td>\n",
       "      <td>1.040360e+06</td>\n",
       "      <td>575492.148707</td>\n",
       "      <td>237</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AA35121</td>\n",
       "      <td>2025-12-25</td>\n",
       "      <td>464</td>\n",
       "      <td>234972720.0</td>\n",
       "      <td>506406.724138</td>\n",
       "      <td>4963146.0</td>\n",
       "      <td>1.040360e+06</td>\n",
       "      <td>575492.148707</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AA23441</td>\n",
       "      <td>2025-12-25</td>\n",
       "      <td>464</td>\n",
       "      <td>234972720.0</td>\n",
       "      <td>506406.724138</td>\n",
       "      <td>4963146.0</td>\n",
       "      <td>1.040360e+06</td>\n",
       "      <td>575492.148707</td>\n",
       "      <td>167</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>23.857143</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AA19754</td>\n",
       "      <td>2025-12-25</td>\n",
       "      <td>464</td>\n",
       "      <td>234972720.0</td>\n",
       "      <td>506406.724138</td>\n",
       "      <td>4963146.0</td>\n",
       "      <td>1.040360e+06</td>\n",
       "      <td>575492.148707</td>\n",
       "      <td>243</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41183</th>\n",
       "      <td>AA8156</td>\n",
       "      <td>2025-12-25</td>\n",
       "      <td>464</td>\n",
       "      <td>234972720.0</td>\n",
       "      <td>506406.724138</td>\n",
       "      <td>4963146.0</td>\n",
       "      <td>1.040360e+06</td>\n",
       "      <td>575492.148707</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41184</th>\n",
       "      <td>AA22986</td>\n",
       "      <td>2025-12-25</td>\n",
       "      <td>464</td>\n",
       "      <td>234972720.0</td>\n",
       "      <td>506406.724138</td>\n",
       "      <td>4963146.0</td>\n",
       "      <td>1.040360e+06</td>\n",
       "      <td>575492.148707</td>\n",
       "      <td>153</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>30.600000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41185</th>\n",
       "      <td>AA19073</td>\n",
       "      <td>2025-12-25</td>\n",
       "      <td>464</td>\n",
       "      <td>234972720.0</td>\n",
       "      <td>506406.724138</td>\n",
       "      <td>4963146.0</td>\n",
       "      <td>1.040360e+06</td>\n",
       "      <td>575492.148707</td>\n",
       "      <td>196</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41186</th>\n",
       "      <td>AA37743</td>\n",
       "      <td>2025-12-25</td>\n",
       "      <td>464</td>\n",
       "      <td>234972720.0</td>\n",
       "      <td>506406.724138</td>\n",
       "      <td>4963146.0</td>\n",
       "      <td>1.040360e+06</td>\n",
       "      <td>575492.148707</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41187</th>\n",
       "      <td>AA6758</td>\n",
       "      <td>2025-12-25</td>\n",
       "      <td>464</td>\n",
       "      <td>234972720.0</td>\n",
       "      <td>506406.724138</td>\n",
       "      <td>4963146.0</td>\n",
       "      <td>1.040360e+06</td>\n",
       "      <td>575492.148707</td>\n",
       "      <td>251</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>83.666667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2025.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>41188 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  event_date  tx_count  total_tx_amount  avg_tx_amount  \\\n",
       "0      AA13249  2025-12-25       464      234972720.0  506406.724138   \n",
       "1      AA16259  2025-12-25       464      234972720.0  506406.724138   \n",
       "2      AA35121  2025-12-25       464      234972720.0  506406.724138   \n",
       "3      AA23441  2025-12-25       464      234972720.0  506406.724138   \n",
       "4      AA19754  2025-12-25       464      234972720.0  506406.724138   \n",
       "...        ...         ...       ...              ...            ...   \n",
       "41183   AA8156  2025-12-25       464      234972720.0  506406.724138   \n",
       "41184  AA22986  2025-12-25       464      234972720.0  506406.724138   \n",
       "41185  AA19073  2025-12-25       464      234972720.0  506406.724138   \n",
       "41186  AA37743  2025-12-25       464      234972720.0  506406.724138   \n",
       "41187   AA6758  2025-12-25       464      234972720.0  506406.724138   \n",
       "\n",
       "       max_tx_amount  std_tx_amount  avg_account_balance  total_clicks  \\\n",
       "0          4963146.0   1.040360e+06        575492.148707           222   \n",
       "1          4963146.0   1.040360e+06        575492.148707           237   \n",
       "2          4963146.0   1.040360e+06        575492.148707           133   \n",
       "3          4963146.0   1.040360e+06        575492.148707           167   \n",
       "4          4963146.0   1.040360e+06        575492.148707           243   \n",
       "...              ...            ...                  ...           ...   \n",
       "41183      4963146.0   1.040360e+06        575492.148707            73   \n",
       "41184      4963146.0   1.040360e+06        575492.148707           153   \n",
       "41185      4963146.0   1.040360e+06        575492.148707           196   \n",
       "41186      4963146.0   1.040360e+06        575492.148707            64   \n",
       "41187      4963146.0   1.040360e+06        575492.148707           251   \n",
       "\n",
       "       total_impressions  total_conversion         ctr  weekday  month  \\\n",
       "0                      1                 0  222.000000      4.0   12.0   \n",
       "1                      1                 0  237.000000      4.0   12.0   \n",
       "2                      1                 0  133.000000      4.0   12.0   \n",
       "3                      7                 0   23.857143      4.0   12.0   \n",
       "4                      1                 0  243.000000      4.0   12.0   \n",
       "...                  ...               ...         ...      ...    ...   \n",
       "41183                  1                 0   73.000000      4.0   12.0   \n",
       "41184                  5                 0   30.600000      4.0   12.0   \n",
       "41185                  1                 0  196.000000      4.0   12.0   \n",
       "41186                  1                 0   64.000000      4.0   12.0   \n",
       "41187                  3                 0   83.666667      4.0   12.0   \n",
       "\n",
       "         year  fraud_label  \n",
       "0      2025.0            1  \n",
       "1      2025.0            1  \n",
       "2      2025.0            1  \n",
       "3      2025.0            1  \n",
       "4      2025.0            1  \n",
       "...       ...          ...  \n",
       "41183  2025.0            1  \n",
       "41184  2025.0            1  \n",
       "41185  2025.0            1  \n",
       "41186  2025.0            1  \n",
       "41187  2025.0            1  \n",
       "\n",
       "[41188 rows x 16 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_fraud_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "89d4bf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering for datetime\n",
    "df['event_date'] = pd.to_datetime(df['event_date'])\n",
    "df['Day'] = df['event_date'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0a6c9843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                0\n",
       "event_date             0\n",
       "tx_count               0\n",
       "total_tx_amount        0\n",
       "avg_tx_amount          0\n",
       "max_tx_amount          0\n",
       "std_tx_amount          0\n",
       "avg_account_balance    0\n",
       "total_clicks           0\n",
       "total_impressions      0\n",
       "total_conversion       0\n",
       "ctr                    0\n",
       "weekday                0\n",
       "month                  0\n",
       "year                   0\n",
       "fraud_label            0\n",
       "Day                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea460885",
   "metadata": {},
   "source": [
    "# Feature Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0528d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"fraud_label\"\n",
    "\n",
    "X = df.drop(columns=[TARGET, \"fraud_reason\"])\n",
    "y = df[TARGET]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d2482f",
   "metadata": {},
   "source": [
    "# Target split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaf6ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972a06e3",
   "metadata": {},
   "source": [
    "# Scalling data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d97ef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919bba8b",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5006d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 64)                1280      \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3393 (13.25 KB)\n",
      "Trainable params: 3393 (13.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_24 (Dense)            (None, 64)                1280      \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3393 (13.25 KB)\n",
      "Trainable params: 3393 (13.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Input(shape=(X_train_scaled.shape[1],)),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        tf.keras.metrics.AUC(name='auc'),\n",
    "        tf.keras.metrics.Precision(name='precision'),\n",
    "        tf.keras.metrics.Recall(name='recall')\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e3493f",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834a0924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1/1 [==============================] - 1s 631ms/step - loss: 0.6931 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 1s 631ms/step - loss: 0.6931 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6926 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6926 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6921 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6921 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6916 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6916 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6911 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6911 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6907 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6907 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6902 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6902 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6897 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6897 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6892 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6892 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6887 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6887 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6882 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6882 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6877 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6877 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 13/50\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6872 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6872 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6867 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6867 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6862 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6862 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6857 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6857 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6852 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6852 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6847 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6847 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6842 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.6842 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6837 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6837 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6832 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6832 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 22/50\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6827 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6827 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6822 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6822 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 24/50\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6817 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6817 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6812 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6812 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6807 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.6807 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6802 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6802 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6798 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6798 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6793 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6793 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6788 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6788 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6783 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6783 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6778 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.6778 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6773 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6773 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6768 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6768 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6763 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6763 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6758 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6758 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6753 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6753 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6749 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6749 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 39/50\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6744 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6744 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6739 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6739 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6734 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.6734 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6729 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6729 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6724 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6724 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6719 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6719 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6714 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6714 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6710 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6710 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6705 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6705 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 48/50\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6700 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.6700 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 49/50\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6695 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6695 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6690 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6690 - auc: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0000e+00 - val_auc: 0.0000e+00 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    validation_data=(X_test_scaled, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76be7437",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65093bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x323527a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n",
      "ROC AUC Score: Cannot be calculated, only one class present in y_test.\n",
      "Test set class distribution: (array([0]), array([1]))\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         1\n",
      "   macro avg       1.00      1.00      1.00         1\n",
      "weighted avg       1.00      1.00      1.00         1\n",
      "\n",
      "ROC AUC Score: Cannot be calculated, only one class present in y_test.\n",
      "Test set class distribution: (array([0]), array([1]))\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = model.predict(X_test_scaled).ravel()\n",
    "y_pred = (y_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ROC AUC only can be calculated using predicted probabilities\n",
    "if len(np.unique(y_test)) >1:\n",
    "    print(\"ROC AUC Score:\", roc_auc_score(y_test, y_pred_prob))\n",
    "else:\n",
    "    print(\"ROC AUC Score: Cannot be calculated, only one class present in y_test.\")\n",
    "    print(f\"Test set class distribution: {np.unique(y_test, return_counts=True)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
